{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTweet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thanos002/Anwendungen_KI/blob/main/BERTweet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh0c4msgE9Wo"
      },
      "source": [
        "#### Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dRSXUB6dXNC_",
        "outputId": "a938e7d6-af1a-4c7d-a9dd-18fe6381f3a9"
      },
      "source": [
        "\"\"\"\n",
        "!git clone https://github.com/huggingface/transformers.git\n",
        "%cd transformers/\n",
        "!pip3 install --upgrade .\n",
        "\"\"\""
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n!git clone https://github.com/huggingface/transformers.git\\n%cd transformers/\\n!pip3 install --upgrade .\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDh8ayPpL1p9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6408071f-4f68-4607-9582-36e5bb7039d8"
      },
      "source": [
        "!pip3 install emoji\n",
        "!pip install transformers sentencepiece"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.9.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBtJqlaBjsA2"
      },
      "source": [
        "def writeResultsInFile(accuracy, f1_score, random_seed):\n",
        "    f = open(\"log\", \"a\")\n",
        "    f.write(f'Random seed : {random_seed}, accuracy : {accuracy}, f1-score : {f1_score}')\n",
        "    f.close()\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHzTumQUx94v"
      },
      "source": [
        "#imports hugging face\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", normalization = True, use_fast=False)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojT7099t1Edi"
      },
      "source": [
        "import transformers\n",
        "import torch\n",
        "import html\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, recall_score, f1_score, accuracy_score, average_precision_score\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "%matplotlib inline\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klREKd8HKX9C"
      },
      "source": [
        "class SATweetDataset(Dataset):\n",
        "\n",
        "  def __init__(self, tweets, tokenizer, max_len, targets=None):\n",
        "    self.tweets = tweets\n",
        "    self.targets = targets if targets is not None else []\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.tweets)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    target = None\n",
        "    tweet = str(self.tweets[item])\n",
        "    if self.targets is not None and item < len(self.targets):\n",
        "      target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      tweet,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      truncation= True,\n",
        "      return_token_type_ids=False,\n",
        "      padding = 'max_length',\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    item_dict = {\n",
        "        'tweet_text': tweet,\n",
        "        'input_ids': encoding['input_ids'].flatten(),\n",
        "        'attention_mask': encoding['attention_mask'].flatten()\n",
        "    }\n",
        "\n",
        "    # Include 'targets' in the dictionary only if they are available\n",
        "    if target is not None:\n",
        "        item_dict['targets'] = torch.tensor(self.targets[item], dtype=torch.long)\n",
        "\n",
        "    return item_dict"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEFSzn4qu7Sx"
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "\n",
        "    ds = SATweetDataset(\n",
        "        tweets=df.body.to_numpy(),\n",
        "        targets=df.target.to_numpy(),\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len\n",
        "    )\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=4\n",
        "    )\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_test_data_loader(df, tokenizer, max_len, batch_size):\n",
        "\n",
        "    ds = SATweetDataset(\n",
        "        tweets=df.body.to_numpy(),\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len\n",
        "    )\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=4\n",
        "    )\n"
      ],
      "metadata": {
        "id": "ZyhxHffsBAs3"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Mf9DdWE3VHN"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = \"vinai/bertweet-base\""
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkHucqHl24cr"
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = bertweet.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    #self.drop = nn.Dropout(p = 0.33)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      return_dict=False\n",
        "    )\n",
        "    #output = self.drop(pooled_output)\n",
        "    output = pooled_output\n",
        "    return self.out(output)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_TCcfwJ6M-x"
      },
      "source": [
        "def train_epoch(model, data_loader, loss_fn, optimizer,  device, n_examples):\n",
        "  model = model.train()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoplX1sK65xv"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNmj61xF7gmg"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  tweets_content = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"tweet_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = nn.functional.softmax(outputs, dim=1)\n",
        "\n",
        "      tweets_content.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "# Check if targets are available in the batch\n",
        "      if 'targets' in d is not None:\n",
        "        targets = d[\"targets\"].to(device)\n",
        "        real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  if real_values:\n",
        "    real_values = torch.stack(real_values).cpu()\n",
        "    return tweets_content, predictions, prediction_probs, real_values\n",
        "  else:\n",
        "    return tweets_content, predictions, prediction_probs"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lczh9wcuQzpO"
      },
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('True sentiment')\n",
        "  plt.xlabel('Predicted sentiment');"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVFBvKC5HNfT"
      },
      "source": [
        "def avg_rec(y_test, y_pred):\n",
        "    rec_n, rec_u, rec_p = recall_score(y_test, y_pred, average=None)\n",
        "    return (1/3) * (rec_n+ rec_u+ rec_p)\n"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AstLK00YHWGz"
      },
      "source": [
        "def f1_np(y_test, y_pred):\n",
        "    f1_n, _,f1_p = f1_score(y_test, y_pred, average=None)\n",
        "    return 0.5*(f1_n+f1_p)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5QTdtJNBhex"
      },
      "source": [
        "\n",
        "\n",
        "####Bonus 2024"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h3EsCsz_PxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd673a6-5b96-4011-b560-312c698fad35"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G1ZMWKCBurn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "4997b976-a684-434a-edca-89142c729336"
      },
      "source": [
        "df_Bonus_train = pd.read_csv('/content/drive/My Drive/train.csv', names = ['id', 'body', 'target'], header=0)\n",
        "df_Bonus_test = pd.read_csv('/content/drive/My Drive/test_no_label.csv', names = ['id', 'body', 'target'], header=0)\n",
        "df_Bonus_train['body'] = df_Bonus_train['body'].apply(html.unescape)\n",
        "df_Bonus_train"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id                                               body  target\n",
              "0          0  #anywere ‚Äú@TheCooleyShow: LA = palm trees and ...       1\n",
              "1          1  RT @OfficialA1King: The face you make when you...       1\n",
              "2          2                     bitch get off my twitter hoe üëä       1\n",
              "3          3            I can taste loud n pussy on my tongue üòù       1\n",
              "4          4  Diabetes galore üòÇüòÇüòÇüòÇüòÇ RT @TIME: Colorado healt...       2\n",
              "...      ...                                                ...     ...\n",
              "19821  19821  RT @_BredDIFFERENT: Niggas will fuck yah good ...       1\n",
              "19822  19822  Soft niggas usually send the hate threw the bi...       1\n",
              "19823  19823  RT @_POCAPetite: stick by his side and don't g...       1\n",
              "19824  19824  RT @Blakeanthony98: ‚Äú@Thompson_Era: ‚Äú@hiagokou...       1\n",
              "19825  19825                 I wanna go to a trash talk concert       2\n",
              "\n",
              "[19826 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd7a3087-8007-4655-8e73-422ebdad6c99\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>body</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>#anywere ‚Äú@TheCooleyShow: LA = palm trees and ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @OfficialA1King: The face you make when you...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>bitch get off my twitter hoe üëä</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>I can taste loud n pussy on my tongue üòù</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Diabetes galore üòÇüòÇüòÇüòÇüòÇ RT @TIME: Colorado healt...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19821</th>\n",
              "      <td>19821</td>\n",
              "      <td>RT @_BredDIFFERENT: Niggas will fuck yah good ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19822</th>\n",
              "      <td>19822</td>\n",
              "      <td>Soft niggas usually send the hate threw the bi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19823</th>\n",
              "      <td>19823</td>\n",
              "      <td>RT @_POCAPetite: stick by his side and don't g...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19824</th>\n",
              "      <td>19824</td>\n",
              "      <td>RT @Blakeanthony98: ‚Äú@Thompson_Era: ‚Äú@hiagokou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19825</th>\n",
              "      <td>19825</td>\n",
              "      <td>I wanna go to a trash talk concert</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19826 rows √ó 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd7a3087-8007-4655-8e73-422ebdad6c99')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd7a3087-8007-4655-8e73-422ebdad6c99 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd7a3087-8007-4655-8e73-422ebdad6c99');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-116c04a6-4cd7-42a1-9479-c49059079a9e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-116c04a6-4cd7-42a1-9479-c49059079a9e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-116c04a6-4cd7-42a1-9479-c49059079a9e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OaOwt0KZlLU"
      },
      "source": [
        "df_Bonus_train['target'] = df_Bonus_train['target'].astype(int)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrZkll3WI1jF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ac5425-87d9-4985-bf8f-7df7cc1cf4d8"
      },
      "source": [
        "token_lens = []\n",
        "for txt in df_Bonus_train.body:\n",
        "  tokens = tokenizer.encode(txt, max_length=128)\n",
        "  token_lens.append(len(tokens))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "LWoigDHHJdM4",
        "outputId": "f8b8eedc-8026-42ba-dbd0-b9ece3d958ce"
      },
      "source": [
        "sns.histplot(token_lens)\n",
        "plt.xlim([0, 256]);\n",
        "plt.xlabel('Token count');"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-K5PJWtKMfw"
      },
      "source": [
        "MAX_LEN = max(token_lens)\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MuG2QNukGvO",
        "outputId": "745673d6-b097-440b-a470-77a2051494ff"
      },
      "source": [
        "MAX_LEN"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEdOYAOCKQMW"
      },
      "source": [
        "RANDOM_SEED = 1993\n",
        "df_train, df_val = train_test_split(df_Bonus_train, test_size=0.1, random_state=RANDOM_SEED)\n",
        "df_test = df_Bonus_test"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ucb3mfSN4Rx"
      },
      "source": [
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO9Xe0K_hwUA",
        "outputId": "68e909ae-044d-4bca-ae06-07ec1ee06f1d"
      },
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['tweet_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HxtkbWVYNOc",
        "outputId": "2ed4d06c-728b-42eb-8489-c37e77369f77"
      },
      "source": [
        "data = next(iter(val_data_loader))\n",
        "data.keys()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['tweet_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PE3N75W_fI0"
      },
      "source": [
        "n_classes = 3\n",
        "class_names = ['hate', 'offensive', 'neither']"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odDx1u9Qhq1H",
        "outputId": "6aff8909-3350-47be-aca4-313e0413203d"
      },
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 68])\n",
            "torch.Size([32, 68])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6kN41fLVuMo"
      },
      "source": [
        "model = SentimentClassifier(n_classes)\n",
        "model = model.to(device)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7uEvVHsVuMo"
      },
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hyH_QnrVuMo",
        "outputId": "c1783a01-2804-42a8-9be1-f3cef85a2bbc"
      },
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "early_stop = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'bertweet_best_model_state.bin')\n",
        "    best_accuracy = val_acc\n",
        "    early_stop = 0\n",
        "  else:\n",
        "      early_stop = early_stop + 1\n",
        "      if early_stop == 5:\n",
        "        break"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3365930501425031 accuracy 0.8868463823348092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.2077772483349808 accuracy 0.9258698940998488\n",
            "\n",
            "Epoch 2/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2190734198697472 accuracy 0.9241158997926359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.20152989504558425 accuracy 0.9263741805345437\n",
            "\n",
            "Epoch 3/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.18646092365385705 accuracy 0.9360533542565712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.22030600490829638 accuracy 0.9152798789712557\n",
            "\n",
            "Epoch 4/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.15609754769525433 accuracy 0.9445721011040745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.2527633553911601 accuracy 0.9062027231467474\n",
            "\n",
            "Epoch 5/30\n",
            "----------\n",
            "Train loss 0.12136832982849156 accuracy 0.9579667096340302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.32396590048747675 accuracy 0.8925869894099849\n",
            "\n",
            "Epoch 6/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.08864926888881164 accuracy 0.9706887855181304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.30315390510124063 accuracy 0.9072112960161373\n",
            "\n",
            "Epoch 7/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.06379361381156765 accuracy 0.9781426890096957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.36348947616774707 accuracy 0.897629853756934\n",
            "\n",
            "CPU times: user 25min 22s, sys: 16.3 s, total: 25min 38s\n",
            "Wall time: 25min 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNXfSUtKtVcd",
        "outputId": "5b32acfa-ca73-4f1a-9121-21d8c4f55a65"
      },
      "source": [
        "model.load_state_dict(torch.load('bertweet_best_model_state.bin'))"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JmbPiNrtVce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aca885c-38dd-428d-af61-e3e531b9cc0f"
      },
      "source": [
        "test_data_loader = create_test_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4ytcOEgtVce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9287586-44b0-4d5e-cdb9-640e29525a35"
      },
      "source": [
        "model.eval()\n",
        "y_tweet_texts, y_pred, y_pred_probs = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")\n"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_list = y_pred.tolist()\n",
        "assert len(y_pred_list) == len(df_test), \"Length of predictions does not match the number of tweets in the DataFrame.\"\n",
        "df_test['Prediction'] = y_pred_list\n",
        "df_test.to_csv('/content/drive/My Drive/test_labeled.csv', index=False)\n"
      ],
      "metadata": {
        "id": "57Xmg1UefeTW"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xungYscDtVce",
        "outputId": "4cbd102b-2a2f-4ae9-d4bd-dbdf6c2aeb2a"
      },
      "source": [
        "# Get predictions for the validation set\n",
        "_, val_predictions, _, val_labels = get_predictions(model, val_data_loader)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(val_labels, val_predictions)\n",
        "print(report)\n"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.48      0.49       104\n",
            "           1       0.95      0.96      0.96      1539\n",
            "           2       0.94      0.89      0.92       340\n",
            "\n",
            "    accuracy                           0.93      1983\n",
            "   macro avg       0.80      0.78      0.79      1983\n",
            "weighted avg       0.93      0.93      0.93      1983\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07poEE_pcwl7"
      },
      "source": [],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I0HdqFJum5X"
      },
      "source": [],
      "execution_count": 141,
      "outputs": []
    }
  ]
}